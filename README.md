# Disaster Response Pipeline Project

The goal of this project to create a Natural Language Processing tool for a web app that classifies disaster messages. This tool can be used for emergency workers to input new messages and get classification results in several categories so that they can send the messages to appropriate disaster relief agencies. The data set is provided by [Figure Eight](https://www.figure-eight.com/). It contains real messages that were sent during disaster events.

## Installation

The packages used are:

- pandas
- scikit-learn
- nltk
- numpy
- flask
- pickle
- json
- plotly
- sqlalchemy
- re

## Files and How to use them
#### app folder
1. templates folders contains two html files. `master.html` builds the front page of the web app. `go.html` is the classification result page.
2. `run.py` uses flask to generate summary plots and model results on the web app.

#### data folder
1. `disaster_messages.csv` contains the real meassages sent during disasters. `disaster_categories.csv` contains labels for the messages.
2. `process_data.py` file creates an ETL pipeline that:
    - Loads and merges the `messages` and `categories` datasets
    - Cleans the data
    - Stores it in a SQLite database
3. `DisasterResponse.db` is the database that is generated by ETL pipeline.

#### model folder
1. `train_classifier.py` creates a machine learning pipeline that:
    - Loads data from the SQLite database
    - Splits the dataset into training and test sets
    - Builds a text processing and machine learning Pipeline
    - Trains and tunes a model using GridSearchCV
    - Outputs results on the test set
    - Exports the final model as a pickle file
2. `classifier.pkl` is the final model trained by ML pipeline.

## Instructions:
1. Run the following commands in the project's root directory to set up your database and model.

    - To run ETL pipeline that cleans data and stores in database
        `python data/process_data.py data/disaster_messages.csv data/disaster_categories.csv data/DisasterResponse.db`
    - To run ML pipeline that trains classifier and saves
        `python models/train_classifier.py data/DisasterResponse.db models/classifier.pkl`

2. Run the following command in the app's directory to run your web app
    `python run.py`


3. Go to http://0.0.0.0:3001/

## Screenshots of the web app
![plots](https://github.com/bkqe7/Disaster-Response-Pipelines/blob/master/screen%20captures/screencapture1.png)

![results](https://github.com/bkqe7/Disaster-Response-Pipelines/blob/master/screen%20captures/screencapture2.png)

## Liscensing, Authors and Acknowledgements
This is a Udacity Data Scientist Nano Degree project. The data set is provided by [Figure Eight](https://www.figure-eight.com/).
